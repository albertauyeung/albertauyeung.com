<!DOCTYPE html>
<html lang="en" class="h-full">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="turbo-cache-control" content="no-cache">

    <!-- Primary Meta Tags -->
    <title>Matrix Factorization: A Simple Tutorial and Implementation in Python</title>
    <meta name="title" content="Matrix Factorization: A Simple Tutorial and Implementation in Python">
    <meta name="description" content="There is probably no need to say that there is too much information on the Web nowadays. Search engines help us a little bit." />

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://albertauyeung.github.io/2017/04/23/python-matrix-factorization.html/">
    <meta property="og:title" content="Matrix Factorization: A Simple Tutorial and Implementation in Python">
    <meta property="og:description" content="There is probably no need to say that there is too much information on the Web nowadays. Search engines help us a little bit.">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://albertauyeung.github.io/2017/04/23/python-matrix-factorization.html/">
    <meta property="twitter:title" content="Matrix Factorization: A Simple Tutorial and Implementation in Python">
    <meta property="twitter:description" content="There is probably no need to say that there is too much information on the Web nowadays. Search engines help us a little bit.">
    
    <script>(function () { var el = document.documentElement, m = localStorage.getItem("doc_theme"), wm = window.matchMedia; if (m === "dark" || (!m && wm && wm("(prefers-color-scheme: dark)").matches)) { el.classList.add("dark") } else { el.classList.remove("dark") } })();</script>

    <link href="/resources/css/retype.css?v=1.10.688667328732" rel="stylesheet" data-turbo-track="reload" />

    <script type="text/javascript" src="/resources/js/config.js?v=1.10.688667328732" defer data-turbo-track="reload"></script>
    <script type="text/javascript" src="/resources/js/retype.js?v=1.10" defer data-turbo-track="reload"></script>
    <script id="prism-js" type="text/javascript" src="/resources/js/prism.js?v=1.10.688667328732" defer></script>
    <link href="/resources/css/katex.css?v=1.10" rel="stylesheet" />
    <script id="katex-js" type="text/javascript" src="/resources/js/katex.js?v=1.10" defer></script>
</head>
    <body>
        <div id="docs-app" class="relative text-base antialiased text-gray-700 bg-white font-body dark:bg-dark-850 dark:text-dark-300">
    <div class="absolute bottom-0 left-0 bg-gray-100 dark:bg-dark-800" style="top: 5rem; right: 50%"></div>

    <header id="docs-site-header" class="sticky top-0 z-30 flex w-full h-16 bg-white border-b border-gray-200 md:h-20 dark:bg-dark-850 dark:border-dark-650">
    <div class="container relative flex items-center justify-between flex-grow pr-6 md:justify-start">
        <!-- Mobile menu button skeleton -->
        <button v-cloak class="skeleton docs-mobile-menu-button flex items-center justify-center flex-shrink-0 overflow-hidden dark:text-white focus:outline-none rounded-full w-10 h-10 ml-3.5 md:hidden"><svg xmlns="http://www.w3.org/2000/svg" class="mb-px flex-shrink-0" width="24" height="24" viewBox="0 0 24 24" role="presentation" style="margin-bottom: 0px;"><g fill="currentColor"><path d="M2 4h20v2H2zM2 11h20v2H2zM2 18h20v2H2z"></path></g></svg></button>
        <div v-cloak id="docs-sidebar-toggle"></div>

        <!-- Logo -->
        <div class="flex items-center justify-between h-full py-2 md:w-75">
            <div class="flex items-center px-2 md:px-6">
                <a id="docs-site-logo" href="/" class="flex items-center leading-snug text-xl">
                    <span class="dark:text-white font-semibold line-clamp-1 md:line-clamp-2">Albert Au Yeung</span>
                </a>
            </div>

            <span class="hidden h-8 border-r md:inline-block dark:border-dark-650"></span>
        </div>

        <div class="flex justify-between md:flex-grow">
            <!-- Top Nav -->
            <nav class="hidden md:flex">
    <ul class="flex flex-col mb-4 md:pl-16 md:mb-0 md:flex-row md:items-center">
        <li class="md:mr-6">
            <a class="inline-flex items-center py-2 md:mb-0 text-sm text-gray-400 whitespace-nowrap transition-colors duration-200 ease-linear md:text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="https://www.linkedin.com/in/albert-au-yeung/">
                <svg xmlns="http://www.w3.org/2000/svg" class="mb-px mr-1" width="18" height="18" viewBox="0 0 24 24" role="presentation">
                    <g fill="currentColor">
                        <path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-11h3v11zm-1.5-12.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.783 1.764-1.75 1.764zm13.5 12.268h-3v-5.604c0-3.368-4-3.113-4 0v5.604h-3v-11h3v1.765c1.396-2.586 7-2.777 7 2.476v6.759z"/>
                    </g>
                </svg>
                <span>LinkedIn</span>
            </a>
        </li>
        <li class="md:mr-6">
            <a class="inline-flex items-center py-2 md:mb-0 text-sm text-gray-400 whitespace-nowrap transition-colors duration-200 ease-linear md:text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="https://www.github.com/albertauyeung">
                <svg xmlns="http://www.w3.org/2000/svg" class="mb-px mr-1" width="18" height="18" viewBox="0 0 24 24" role="presentation">
                    <g fill="currentColor">
                        <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                    </g>
                </svg>
                <span>Github</span>
            </a>
        </li>
        <li class="md:mr-6">
            <a class="inline-flex items-center py-2 md:mb-0 text-sm text-gray-400 whitespace-nowrap transition-colors duration-200 ease-linear md:text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="https://twitter.com/albertauyeung">
                <svg xmlns="http://www.w3.org/2000/svg" class="mb-px mr-1" width="18" height="18" viewBox="0 0 24 24" role="presentation">
                    <g fill="currentColor">
                        <g fill="currentColor"><path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-.139 9.237c.209 4.617-3.234 9.765-9.33 9.765-1.854 0-3.579-.543-5.032-1.475 1.742.205 3.48-.278 4.86-1.359-1.437-.027-2.649-.976-3.066-2.28.515.098 1.021.069 1.482-.056-1.579-.317-2.668-1.739-2.633-3.26.442.246.949.394 1.486.411-1.461-.977-1.875-2.907-1.016-4.383 1.619 1.986 4.038 3.293 6.766 3.43-.479-2.053 1.08-4.03 3.199-4.03.943 0 1.797.398 2.395 1.037.748-.147 1.451-.42 2.086-.796-.246.767-.766 1.41-1.443 1.816.664-.08 1.297-.256 1.885-.517-.439.656-.996 1.234-1.639 1.697z"></path></g>
                    </g>
                </svg>
                <span>Twitter</span>
            </a>
        </li>
    </ul>
</nav>

            <!-- Header Right Skeleton -->
            <div v-cloak class="flex justify-end flex-grow skeleton">

                <!-- Search input mock -->
                <div class="relative hidden w-40 lg:block lg:max-w-sm lg:ml-auto">
                    <div class="absolute flex items-center justify-center h-full pl-3 dark:text-dark-300">
                        <svg xmlns="http://www.w3.org/2000/svg" class="icon-base" width="16" height="16" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation"  style="margin-bottom: 1px;"><g fill="currentColor" ><path d="M21.71 20.29l-3.68-3.68A8.963 8.963 0 0020 11c0-4.96-4.04-9-9-9s-9 4.04-9 9 4.04 9 9 9c2.12 0 4.07-.74 5.61-1.97l3.68 3.68c.2.19.45.29.71.29s.51-.1.71-.29c.39-.39.39-1.03 0-1.42zM4 11c0-3.86 3.14-7 7-7s7 3.14 7 7c0 1.92-.78 3.66-2.04 4.93-.01.01-.02.01-.02.01-.01.01-.01.01-.01.02A6.98 6.98 0 0111 18c-3.86 0-7-3.14-7-7z" ></path></g></svg>
                    </div>

                    <input class="w-full h-10 transition-colors duration-200 ease-in bg-gray-200 border border-transparent rounded md:text-sm hover:bg-white hover:border-gray-300 focus:outline-none focus:bg-white focus:border-gray-500 dark:bg-dark-600 dark:border-dark-600 placeholder-gray-400 dark:placeholder-dark-400"
                    style="padding: 0.625rem 0.75rem 0.625rem 2rem" type="text" placeholder="Search docs" />
                </div>

                <!-- Mobile search button mock -->
                <div class="flex items-center justify-center w-10 h-10 lg:hidden">
                    <svg xmlns="http://www.w3.org/2000/svg" class="flex-shrink-0 icon-base" width="20" height="20" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation"  style="margin-bottom: 0px;"><g fill="currentColor" ><path d="M21.71 20.29l-3.68-3.68A8.963 8.963 0 0020 11c0-4.96-4.04-9-9-9s-9 4.04-9 9 4.04 9 9 9c2.12 0 4.07-.74 5.61-1.97l3.68 3.68c.2.19.45.29.71.29s.51-.1.71-.29c.39-.39.39-1.03 0-1.42zM4 11c0-3.86 3.14-7 7-7s7 3.14 7 7c0 1.92-.78 3.66-2.04 4.93-.01.01-.02.01-.02.01-.01.01-.01.01-.01.02A6.98 6.98 0 0111 18c-3.86 0-7-3.14-7-7z" ></path></g></svg>
                </div>

                <!-- Dark mode switch placehokder -->
                <div class="w-10 h-10 lg:ml-2"></div>

                <!-- History button mock -->
                <div class="flex items-center justify-center w-10 h-10" style="margin-right: -0.625rem;">
                    <svg xmlns="http://www.w3.org/2000/svg" class="flex-shrink-0 icon-base" width="22" height="22" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation"  style="margin-bottom: 0px;"><g fill="currentColor" ><g ><path d="M12.01 6.01c-.55 0-1 .45-1 1V12a1 1 0 00.4.8l3 2.22a.985.985 0 001.39-.2.996.996 0 00-.21-1.4l-2.6-1.92V7.01c.02-.55-.43-1-.98-1z"></path><path d="M12.01 1.91c-5.33 0-9.69 4.16-10.05 9.4l-.29-.26a.997.997 0 10-1.34 1.48l1.97 1.79c.19.17.43.26.67.26s.48-.09.67-.26l1.97-1.79a.997.997 0 10-1.34-1.48l-.31.28c.34-4.14 3.82-7.41 8.05-7.41 4.46 0 8.08 3.63 8.08 8.09s-3.63 8.08-8.08 8.08c-2.18 0-4.22-.85-5.75-2.4a.996.996 0 10-1.42 1.4 10.02 10.02 0 007.17 2.99c5.56 0 10.08-4.52 10.08-10.08.01-5.56-4.52-10.09-10.08-10.09z"></path></g></g></svg>
                </div>
            </div>

            <div v-cloak class="flex items-center justify-end flex-grow">
                <div id="docs-mobile-search-button"></div>
                <doc-search-desktop></doc-search-desktop>

                <doc-theme-switch class="lg:ml-2"></doc-theme-switch>
                <doc-history></doc-history>
            </div>
        </div>
    </div>
</header>


    <div class="container relative flex bg-white">
        <!-- Sidebar Skeleton -->
<div v-cloak class="fixed flex flex-col flex-shrink-0 duration-300 ease-in-out bg-gray-100 border-gray-200 sidebar top-20 w-75 border-r h-screen md:sticky transition-transform skeleton dark:bg-dark-800 dark:border-dark-650">

    <!-- Render this div, if config.showSidebarFilter is `true` -->
    <div class="flex items-center h-16 px-6">
        <input class="w-full h-8 px-3 py-2 transition-colors duration-200 ease-linear bg-white border border-gray-200 rounded shadow-none text-sm focus:outline-none focus:border-gray-600 dark:bg-dark-600 dark:border-dark-600" type="text" placeholder="Filter" />
    </div>

    <div class="pl-6 mb-4 mt-1">
        <div class="w-32 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
        <div class="w-48 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
        <div class="w-40 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
        <div class="w-32 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
        <div class="w-48 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
        <div class="w-40 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
    </div>

    <div class="flex-shrink-0 mt-auto bg-transparent dark:border-dark-650">
        <a
    class="flex items-center justify-center flex-nowrap h-16 text-gray-400 dark:text-dark-400 hover:text-gray-700 dark:hover:text-dark-300 transition-colors duration-150 ease-in"
    target="_blank"
    href="https://retype.com/"
    rel="noopener"
>
    <span class="text-xs whitespace-nowrap">Powered by</span>
    <svg xmlns="http://www.w3.org/2000/svg" class="ml-2" fill="currentColor" width="96" height="20" overflow="visible"><path d="M0 0v20h13.59V0H0zm11.15 17.54H2.44V2.46h8.71v15.08zM15.8 20h2.44V4.67L15.8 2.22zM20.45 6.89V20h2.44V9.34z"/><g><path d="M40.16 8.44c0 1.49-.59 2.45-1.75 2.88l2.34 3.32h-2.53l-2.04-2.96h-1.43v2.96h-2.06V5.36h3.5c1.43 0 2.46.24 3.07.73s.9 1.27.9 2.35zm-2.48 1.1c.26-.23.38-.59.38-1.09 0-.5-.13-.84-.4-1.03s-.73-.28-1.39-.28h-1.54v2.75h1.5c.72 0 1.2-.12 1.45-.35zM51.56 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92h4.74v1.83h-6.79V5.36h6.64zM60.09 7.15v7.48h-2.06V7.15h-2.61V5.36h7.28v1.79h-2.61zM70.81 14.64h-2.06v-3.66l-3.19-5.61h2.23l1.99 3.45 1.99-3.45H74l-3.19 5.61v3.66zM83.99 6.19c.65.55.97 1.4.97 2.55s-.33 1.98-1 2.51-1.68.8-3.04.8h-1.23v2.59h-2.06V5.36h3.26c1.42 0 2.45.28 3.1.83zm-1.51 3.65c.25-.28.37-.69.37-1.22s-.16-.92-.48-1.14c-.32-.23-.82-.34-1.5-.34H79.7v3.12h1.38c.68 0 1.15-.14 1.4-.42zM95.85 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92H96v1.83h-6.79V5.36h6.64z"/></g></svg>
</a>

    </div>
</div>

<!-- Sidebar component -->
<doc-sidebar v-cloak>
    <template #sidebar-footer>
        <div
            class="flex-shrink-0 mt-auto border-t md:bg-transparent md:border-none dark:border-dark-650"
        >

            <div class="py-3 px-6 md:hidden border-b dark:border-dark-650">
                <nav>
                    <ul class="flex flex-wrap justify-center items-center">
                        <li class="mr-6">
                            <a class="block py-1 text-sm whitespace-nowrap transition-colors duration-200 ease-linear text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="https://www.linkedin.com/in/albert-au-yeung/">LinkedIn</a>
                        </li>
                        <li class="mr-6">
                            <a class="block py-1 text-sm whitespace-nowrap transition-colors duration-200 ease-linear text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="https://www.github.com/albertauyeung">Github</a>
                        </li>
                        <li class="mr-6">
                            <a class="block py-1 text-sm whitespace-nowrap transition-colors duration-200 ease-linear text-blue-500 dark:text-blue-400 hover:text-blue-800 dark:hover:text-blue-200" href="https://twitter.com/albertauyeung">Twitter</a>
                        </li>
                    </ul>
                </nav>
            </div>

            <a
    class="flex items-center justify-center flex-nowrap h-16 text-gray-400 dark:text-dark-400 hover:text-gray-700 dark:hover:text-dark-300 transition-colors duration-150 ease-in"
    target="_blank"
    href="https://retype.com/"
    rel="noopener"
>
    <span class="text-xs whitespace-nowrap">Powered by</span>
    <svg xmlns="http://www.w3.org/2000/svg" class="ml-2" fill="currentColor" width="96" height="20" overflow="visible"><path d="M0 0v20h13.59V0H0zm11.15 17.54H2.44V2.46h8.71v15.08zM15.8 20h2.44V4.67L15.8 2.22zM20.45 6.89V20h2.44V9.34z"/><g><path d="M40.16 8.44c0 1.49-.59 2.45-1.75 2.88l2.34 3.32h-2.53l-2.04-2.96h-1.43v2.96h-2.06V5.36h3.5c1.43 0 2.46.24 3.07.73s.9 1.27.9 2.35zm-2.48 1.1c.26-.23.38-.59.38-1.09 0-.5-.13-.84-.4-1.03s-.73-.28-1.39-.28h-1.54v2.75h1.5c.72 0 1.2-.12 1.45-.35zM51.56 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92h4.74v1.83h-6.79V5.36h6.64zM60.09 7.15v7.48h-2.06V7.15h-2.61V5.36h7.28v1.79h-2.61zM70.81 14.64h-2.06v-3.66l-3.19-5.61h2.23l1.99 3.45 1.99-3.45H74l-3.19 5.61v3.66zM83.99 6.19c.65.55.97 1.4.97 2.55s-.33 1.98-1 2.51-1.68.8-3.04.8h-1.23v2.59h-2.06V5.36h3.26c1.42 0 2.45.28 3.1.83zm-1.51 3.65c.25-.28.37-.69.37-1.22s-.16-.92-.48-1.14c-.32-.23-.82-.34-1.5-.34H79.7v3.12h1.38c.68 0 1.15-.14 1.4-.42zM95.85 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92H96v1.83h-6.79V5.36h6.64z"/></g></svg>
</a>

        </div>
    </template>
</doc-sidebar>


        <div class="flex-grow min-w-0 dark:bg-dark-850">
            <!-- Render "toolbar" template here on api pages --><!-- Render page content -->
            <div class="flex">
    <div class="flex-grow min-w-0 px-6 md:px-16">
        <main class="relative pt-6 pb-16">
            <div class="docs-markdown" id="docs-content">
                <!-- Rendered if sidebar right is enabled -->
                <div id="docs-sidebar-right-toggle"></div>
               
                <!-- Page content  -->
<doc-anchor-target id="matrix-factorization-a-simple-tutorial-and-implementation-in-python" class="break-words">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#matrix-factorization-a-simple-tutorial-and-implementation-in-python">#</doc-anchor-trigger>
        <span>Matrix Factorization: A Simple Tutorial and Implementation in Python</span>
    </h1>
</doc-anchor-target>
<div class="-mt-3 mb-12 flex flex-wrap text-sm text-gray-400 dark:text-dark-350">
    <div class="flex items-center flex-shrink-0">Published&nbsp;<span>2017-04-23</span></div>
</div>

<p>There is probably no need to say that there is too much information on the Web nowadays. Search engines help us a little bit. What is better is to have something interesting recommended to us automatically without asking. Indeed, from as simple as a list of the most popular questions and answers on <a href="https://www.quora.com/">Quora</a> to some more personalized recommendations we received on <a href="https://www.amazon.com">Amazon</a>, we are usually offered recommendations on the Web.</p>
<p>Recommendations can be generated by a wide range of algorithms. While user-based or item-based <a href="http://en.wikipedia.org/wiki/Collaborative_filtering">collaborative filtering</a> methods are simple and intuitive, <a href="https://en.wikipedia.org/wiki/Matrix_decomposition">matrix factorization</a> techniques are usually more effective because they allow us to discover the latent features underlying the interactions between users and items. Of course, matrix factorization is simply a mathematical tool for playing around with matrices, and is therefore applicable in many scenarios where one would like to find out something hidden under the data.</p>
<p>In this tutorial, we will go through the basic ideas and the mathematics of matrix factorization, and then we will present a simple implementation in <a href="http://www.python.org">Python</a>. We will proceed with the assumption that we are dealing with user ratings (e.g. an integer score from the range of 1 to 5) of items in a recommendation system.</p>
<doc-anchor-target id="basic-idea">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#basic-idea">#</doc-anchor-trigger>
        <span>Basic Idea</span>
    </h2>
</doc-anchor-target>
<p>Just as its name suggests, matrix factorization is to, obviously, factorize a matrix, i.e. to find out two (or more) matrices such that when you multiply them you will get back the original matrix.</p>
<p>As mentioned above, from an application point of view, matrix factorization can be used to discover latent features underlying the interactions between two different kinds of entities. (Of course, you can consider more than two kinds of entities and you will be dealing with tensor factorization, which would be more complicated.) And one obvious application is to predict ratings in collaborative filtering.</p>
<p>In a recommendation system such as <a href="http://www.netflix.com/">Netflix</a> or <a href="http://movielens.umn.edu/">MovieLens</a>, there is a group of users and a set of items (movies for the above two systems). Given that each users have rated some items in the system, we would like to predict how the users would rate the items that they have not yet rated, such that we can make recommendations to the users. In this case, all the information we have about the existing ratings can be represented in a matrix. Assume now we have 5 users and 10 items, and ratings are integers ranging from 1 to 5, the matrix may look something like this (a hyphen means that the user has not yet rated the movie):</p>
<center>
<table>
<tbody>
<tr>
<td></td>
<td><strong>D1</strong></td>
<td><strong>D2</strong></td>
<td><strong>D3</strong></td>
<td><strong>D4</strong></td>
</tr>
<tr>
<td><strong>U1</strong></td>
<td>5</td><td>3</td><td>-</td><td>1</td>
</tr>
<tr>
<td><strong>U2</strong></td>
<td>4</td><td>-</td><td>-</td><td>1</td>
</tr>
<tr>
<td><strong>U3</strong></td>
<td>1</td><td>1</td><td>-</td><td>5</td>
</tr>
<tr>
<td><strong>U4</strong></td>
<td>1</td><td>-</td><td>-</td><td>4</td>
</tr>
<tr>
<td><strong>U5</strong></td>
<td>-</td><td>1</td><td>5</td><td>4</td>
</tr>
</tbody>
</table>
</center><br/>
<p>Hence, the task of predicting the missing ratings can be considered as filling in the blanks (the hyphens in the matrix) such that the values would be consistent with the existing ratings in the matrix.</p>
<p>The intuition behind using matrix factorization to solve this problem is that there should be some latent features that determine how a user rates an item. For example, two users would give high ratings to a certain movie if they both like the actors or actresses in the movie, or if the movie is an action movie, which is a genre preferred by both users.</p>
<p>Hence, if we can discover these latent features, we should be able to predict a rating with respect to a certain user and a certain item, because the features associated with the user should match with the features associated with the item.</p>
<p>In trying to discover the different features, we also make the assumption that the <strong>number of features</strong> would be smaller than the <strong>number of users</strong> and the <strong>number of items</strong>. It should not be difficult to understand this assumption because clearly it would not be reasonable to assume that each user is associated with a unique feature (although this is not impossible). And anyway if this is the case there would be no point in making recommendations, because each of these users would not be interested in the items rated by other users. Similarly, the same argument applies to the items.</p>
<doc-anchor-target id="the-maths-of-matrix-factorization">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#the-maths-of-matrix-factorization">#</doc-anchor-trigger>
        <span>The Maths of Matrix Factorization</span>
    </h2>
</doc-anchor-target>
<p>Having discussed the intuition behind matrix factorization, we can now go on to work on the mathematics. Firstly, we have a set <span class="math">U</span> of users, and a set <span class="math">D</span> of items. Let <span class="math">\mathbf{R}</span> of size <span class="math">\|U\| \times \|D\|</span> be the matrix that contains all the ratings that the users have assigned to the items. Also, we assume that we would like to discover <span class="math">K</span> latent features. Our task, then, is to find two matrics <span class="math">\mathbf{P}</span> (of size <span class="math">\|U\| \times \|K\|</span>) and <span class="math">\mathbf{Q}</span> (of size <span class="math">\|D\| \times \|K\|</span>) such that their product apprioximates <span class="math">\mathbf{R}</span>:</p>
<center>
$$\mathbf{R} \approx \mathbf{P} \times \mathbf{Q}^T = \hat{\mathbf{R}}$$
</center><br/>
<p>In this way, each row of <span class="math">\mathbf{P}</span> would represent the strength of the associations between <strong>a user and the features</strong>. Similarly, each row of <span class="math">\mathbf{Q}</span>  would represent the strength of the associations between <strong>an item and the features</strong>. To get the prediction of a rating of an item <span class="math">d_j</span> by <span class="math">u_i</span>, we can calculate the dot product of their vectors:</p>
<center>
$\hat{r}_{ij} = p_i^T q_j = \sum_{k=1}^K{p_{ik} q_{kj}}$
</center><br/>
<p>Now, we have to find a way to obtain <span class="math">\mathbf{P}</span> and <span class="math">\mathbf{Q}</span>. One way to approach this problem is the first intialize the two matrices with some values, calculate how <strong>different</strong> their product is to <span class="math">\mathbf{M}</span>, and then try to minimize this difference iteratively. Such a method is called gradient descent, aiming at finding a local minimum of the difference.</p>
<p>The difference here, usually called the <strong>error</strong> between the estimated rating and the real rating, can be calculated by the following equation for each user-item pair:</p>
<center>
$e_{ij}^2 = (r_{ij} - \hat{r}_{ij})^2 = (r_{ij} - \sum_{k=1}^K{p_{ik}q_{kj}})^2$
</center><br/>
<p>Here we consider the <strong>squared error</strong> because the estimated rating can be either higher or lower than the real rating.</p>
<p>To minimize the error, we have to know in which direction we have to modify the values of <span class="math">p_{ik}</span> and <span class="math">q_{kj}</span>. In other words, we need to know the gradient at the current values, and therefore we differentiate the above equation with respect to these two variables separately:</p>
<center>
$\frac{\partial}{\partial p_{ik}}e_{ij}^2 = -2(r_{ij} - \hat{r}_{ij})(q_{kj}) = -2 e_{ij} q_{kj}$
<p><span class="math">\frac{\partial}{\partial q_{ik}}e_{ij}^2 = -2(r_{ij} - \hat{r}_{ij})(p_{ik}) = -2 e_{ij} p_{ik}</span></p>
</center><br/>
<p>Having obtained the gradient, we can now formulate the <strong>update rules</strong> for both <span class="math">p_{ik}</span> and <span class="math">q_{kj}</span>:</p>
<center>
$p'_{ik} = p_{ik} + \alpha \frac{\partial}{\partial p_{ik}}e_{ij}^2 = p_{ik} + 2\alpha e_{ij} q_{kj}$
<p><span class="math">q'_{kj} = q_{kj} + \alpha \frac{\partial}{\partial q_{kj}}e_{ij}^2 = q_{kj} + 2\alpha e_{ij} p_{ik}</span></p>
</center><br/>
<p>Here, <span class="math">\alpha</span> is a constant whose value determines the <strong>rate of approaching the minimum</strong>. Usually we will choose a small value for <span class="math">\alpha</span>, say 0.0002. This is because if we make too large a step towards the minimum we may run into the risk of missing the minimum and end up oscillating around the minimum.</p>
<p>A question might have come to your mind by now: if we find two matrices <span class="math">\mathbf{P}</span> and <span class="math">\mathbf{Q}</span> such that <span class="math">\mathbf{P} \times \mathbf{Q}</span> approximates <span class="math">\mathbf{R}</span>, isn&#x27;t that our predictions of all the unseen ratings will be zeros? In fact, we are not really trying to come up with <span class="math">\mathbf{P}</span> and <span class="math">\mathbf{Q}</span> such that we can reproduce <span class="math">\mathbf{R}</span> exactly. Instead, we will only try to minimise the errors of the <strong>observed</strong> user-item pairs. In other words, if we let <span class="math">T</span> be a set of tuples, each of which is in the form of <span class="math">(u_i, d_j, r_{ij})</span>, such that <span class="math">T</span> contains all the observed user-item pairs together with the associated ratings, we are only trying to minimise every <span class="math">e_{ij}</span> for <span class="math">(u_i, d_j, r_{ij}) \in T</span>. (In other words, <span class="math">T</span> is our set of <strong>training data</strong>.) As for the rest of the unknowns, we will be able to determine their values once the associations between the users, items and features have been learnt.</p>
<p>Using the above update rules, we can then iteratively perform the operation until the error converges to its minimum. We can check the overall error as calculated using the following equation and determine when we should stop the process.</p>
<center>
$E = \sum_{(u_i, d_j, r_{ij}) \in T}{e_{ij}} = \sum_{(u_i,d_j,r_{ij}) \in T}{(r_{ij} - \sum_{k=1}^K{p_{ik}q_{kj}})^2}$
</center><br/>
<doc-anchor-target id="regularization">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#regularization">#</doc-anchor-trigger>
        <span>Regularization</span>
    </h2>
</doc-anchor-target>
<p>The above algorithm is a very basic algorithm for factorizing a matrix. There are a lot of methods to make things look more complicated. A common extension to this basic algorithm is to introduce <a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)"><strong>regularization</strong></a> to avoid <strong>overfitting</strong>. This is done by adding a parameter <span class="math">\beta</span> and modify the squared error as follows:</p>
<center>
$e_{ij}^2 = (r_{ij} - \sum_{k=1}^K{p_{ik}q_{kj}})^2 + \frac{\beta}{2} \sum_{k=1}^K{(||P||^2 + ||Q||^2)}$
</center><br/>
<p>In other words, the new parameter <span class="math">\beta</span> is used to control the <strong>magnitudes</strong> of the user-feature and item-feature vectors such that <span class="math">P</span> and <span class="math">Q</span> would give a good approximation of <span class="math">R</span> without having to contain large numbers. In practice, <span class="math">\beta</span> is set to some values in the order of 0.02. The new update rules for this squared error can be obtained by a procedure similar to the one described above. The new update rules are as follows:</p>
<center>
$p'_{ik} = p_{ik} + \alpha \frac{\partial}{\partial p_{ik}}e_{ij}^2 = p_{ik} + \alpha(2 e_{ij} q_{kj} - \beta p_{ik} )$
<p><span class="math">q'_{kj} = q_{kj} + \alpha \frac{\partial}{\partial q_{kj}}e_{ij}^2 = q_{kj} + \alpha(2 e_{ij} p_{ik} - \beta q_{kj} )</span></p>
</center><br/>
<doc-anchor-target id="adding-biases">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#adding-biases">#</doc-anchor-trigger>
        <span>Adding Biases</span>
    </h2>
</doc-anchor-target>
<p>When predicting the ratings of users given to items, it is useful to consider how ratings are generated. In the above discussion, we have assumed that ratings are generated based on matching the users preferences on some latent factors and the items&#x27; characteristics on the latent factors. Actually, it may also be helpful to consider additional factors here.</p>
<p>For example, we can assume that when a rating is generated, some <strong>biases</strong> may also contribute to the ratings. In particular, every user may have his or her own bias, meaning that he or she may tend to rate items higher or lower than the others. In movie ratings, if a user is a serious movie watcher, he or she may tend to give lower ratings, when compared to another user who generally enjoys movies as long as they are not too boring. A similar idea can also be applied to the items being rated.</p>
<p>Hence, in the equal of predicting a rating, we can also add these biases in order to better model how a rating is generated:</p>
<center>
$\hat{r}_{ij} = b + bu_i + bd_j + \sum_{k=1}^k{p_{ik} q_{kj}}$
</center><br/>
<p>where <span class="math">b</span> is the global bias (which can be easily estimated by using the mean of all ratings), <span class="math">bu_i</span> is the bias of user <span class="math">i</span>, and <span class="math">bd_j</span> is the bias of item <span class="math">j</span>.</p>
<p>Using the same steps mentioned above, we can derive the update rules for the user biases and item biases easily:</p>
<center>
$bu'_i = bu_i + \alpha \times (e_{ij} - \beta bu_i)$
<p><span class="math">bd'_j = bd_j + \alpha \times (e_{ij} - \beta bd_j)</span></p>
</center><br/>
<p>In practice, the process of factorization will converge faster if biases are included in the model.</p>
<doc-anchor-target id="a-simple-implementation-in-python">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#a-simple-implementation-in-python">#</doc-anchor-trigger>
        <span>A Simple Implementation in Python</span>
    </h2>
</doc-anchor-target>
<p>Once we have derived the update rules as described above, it actually becomes very straightforward to implement the algorithm. The following is a function that implements the algorithm in Python using the <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent"><strong>stochastic gradient descent</strong></a> algorithm. Note that this implementation requires the <a href="http://numpy.scipy.org/"><strong>Numpy</strong></a> module.</p>
<div class="codeblock-wrapper"><doc-codeblock>
<pre class="language-python"><code v-pre class="language-python">import numpy as np

class MF():

    def __init__(self, R, K, alpha, beta, iterations):
        &quot;&quot;&quot;
        Perform matrix factorization to predict empty
        entries in a matrix.

        Arguments
        - R (ndarray)   : user-item rating matrix
        - K (int)       : number of latent dimensions
        - alpha (float) : learning rate
        - beta (float)  : regularization parameter
        &quot;&quot;&quot;

        self.R = R
        self.num_users, self.num_items = R.shape
        self.K = K
        self.alpha = alpha
        self.beta = beta
        self.iterations = iterations

    def train(self):
        # Initialize user and item latent feature matrice
        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))
        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))

        # Initialize the biases
        self.b_u = np.zeros(self.num_users)
        self.b_i = np.zeros(self.num_items)
        self.b = np.mean(self.R[np.where(self.R != 0)])

        # Create a list of training samples
        self.samples = [
            (i, j, self.R[i, j])
            for i in range(self.num_users)
            for j in range(self.num_items)
            if self.R[i, j] &gt; 0
        ]

        # Perform stochastic gradient descent for number of iterations
        training_process = []
        for i in range(self.iterations):
            np.random.shuffle(self.samples)
            self.sgd()
            mse = self.mse()
            training_process.append((i, mse))
            if (i+1) % 10 == 0:
                print(&quot;Iteration: %d ; error = %.4f&quot; % (i+1, mse))

        return training_process

    def mse(self):
        &quot;&quot;&quot;
        A function to compute the total mean square error
        &quot;&quot;&quot;
        xs, ys = self.R.nonzero()
        predicted = self.full_matrix()
        error = 0
        for x, y in zip(xs, ys):
            error += pow(self.R[x, y] - predicted[x, y], 2)
        return np.sqrt(error)

    def sgd(self):
        &quot;&quot;&quot;
        Perform stochastic graident descent
        &quot;&quot;&quot;
        for i, j, r in self.samples:
            # Computer prediction and error
            prediction = self.get_rating(i, j)
            e = (r - prediction)

            # Update biases
            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])
            self.b_i[j] += self.alpha * (e - self.beta * self.b_i[j])

            # Update user and item latent feature matrices
            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])
            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])

    def get_rating(self, i, j):
        &quot;&quot;&quot;
        Get the predicted rating of user i and item j
        &quot;&quot;&quot;
        prediction = self.b + self.b_u[i] + self.b_i[j] + self.P[i, :].dot(self.Q[j, :].T)
        return prediction

    def full_matrix(self):
        &quot;&quot;&quot;
        Computer the full matrix using the resultant biases, P and Q
        &quot;&quot;&quot;
        return self.b + self.b_u[:,np.newaxis] + self.b_i[np.newaxis:,] + self.P.dot(self.Q.T)</code></pre>
</doc-codeblock></div>
<p>We can try to apply it to our example mentioned above and see what we would get. Below is a code snippet in Python for running the example.</p>
<div class="codeblock-wrapper"><doc-codeblock>
<pre class="language-python"><code v-pre class="language-python">R = np.array([
    [5, 3, 0, 1],
    [4, 0, 0, 1],
    [1, 1, 0, 5],
    [1, 0, 0, 4],
    [0, 1, 5, 4],
])

mf = MF(R, K=2, alpha=0.1, beta=0.01, iterations=20)</code></pre>
</doc-codeblock></div>
<p>And the matrix obtained from the above process would look something like this:</p>
<div class="codeblock-wrapper"><doc-codeblock>
<pre class="language-python"><code v-pre class="language-python">[[ 4.99  3.    3.34  1.01]
 [ 4.    3.18  2.98  1.01]
 [ 1.02  0.96  5.54  4.97]
 [ 1.    0.6   4.78  3.97]
 [ 1.53  1.05  4.94  4.03]]</code></pre>
</doc-codeblock></div>
<p>We can see that for existing ratings we have the approximations very close to the true values, and we also get some &#x27;predictions&#x27; of the unknown values. In this simple example, we can easily see that <span class="math">U1</span> and <span class="math">U2</span> have similar taste and they both rated <span class="math">D1</span> and <span class="math">D2</span> high, while the rest of the users preferred <span class="math">D3</span>, <span class="math">D4</span> and <span class="math">D5</span>. When the number of features (<span class="math">K</span> in the Python code) is 2, the algorithm is able to associate the users and items to two different features, and the predictions also follow these associations. For example, we can see that the predicted rating of <span class="math">U4</span> on <span class="math">D3</span> is 4.78, because <span class="math">U4</span> and <span class="math">U5</span> both rated <span class="math">D4</span> high.</p>
<doc-anchor-target id="further-information">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#further-information">#</doc-anchor-trigger>
        <span>Further Information</span>
    </h2>
</doc-anchor-target>
<p>We have discussed the intuitive meaning of the technique of matrix factorization and its use in collaborative filtering. In fact, there are many different extensions to the above technique. An important extension is the requirement that all the elements of the factor matrices <span class="math">\mathbf{P}</span> and <span class="math">\mathbf{Q}</span> in the above example) should be <strong>non-negative</strong>. In this case it is called <a href="https://en.wikipedia.org/wiki/Non-negative_matrix_factorization">non-negative matrix factorization (NMF)</a>. One advantage of NMF is that it results in intuitive meanings of the resultant matrices. Since no elements are negative, the process of multiplying the resultant matrices to get back the original matrix would not involve subtraction, and can be considered as a process of generating the original data by linear combinations of the latent features.</p>
<doc-anchor-target id="source-code">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#source-code">#</doc-anchor-trigger>
        <span>Source Code</span>
    </h2>
</doc-anchor-target>
<p>An example can be found at this <a href="https://nbviewer.jupyter.org/github/albertauyeung/matrix-factorization-in-python/blob/master/mf.ipynb">IPython notebok</a>. It is also available at my Github account in <a href="https://github.com/albertauyeung/matrix-factorization-in-python">this repository</a>.</p>
<doc-anchor-target id="references">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#references">#</doc-anchor-trigger>
        <span>References</span>
    </h2>
</doc-anchor-target>
<p>There have been quite a lot of references on matrix factorization. Below are some of the related papers:</p>
<ul>
<li>Gábor Takács et al (2008). <a href="http://portal.acm.org/citation.cfm?id=1454049">Matrix factorization and neighbor based algorithms for the Netflix prize problem</a>In: Proceedings of the 2008 ACM Conference on Recommender Systems, Lausanne, Switzerland, October 23 - 25, 267-274.</li>
<li>Patrick Ott (2008). <a href="http://www.comp.leeds.ac.uk/ott/dl/mf_ott.pdf">Incremental Matrix Factorization for Collaborative Filtering</a>. Science, Technology and Design 01/2008, Anhalt University of Applied Sciences.</li>
<li>Daniel D. Lee and H. Sebastian Seung (2001). <a href="http://hebb.mit.edu/people/seung/papers/nmfconverge.pdf">Algorithms for Non-negative Matrix Factorization</a>. Advances in Neural Information Processing Systems 13: Proceedings of the 2000 Conference. MIT Press. pp. 556–562.</li>
<li>Daniel D. Lee and H. Sebastian Seung (1999). <a href="http://www.nature.com/nature/journal/v401/n6755/abs/401788a0.html">Learning the parts of objects by non-negative matrix factorization</a>. Nature, Vol. 401, No. 6755. (21 October 1999), pp. 788-791.</li>
</ul>


<div class="flex items-center mt-6 mb-6">
    <span>
        <a href="/tags/">
            <svg class="inline-block -mb-px mr-1.5 text-blue-500 dark:text-blue-400" xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" overflow="visible" fill="currentColor"><g><path d="M21.3 9.88l-8.59-8.59C12.52 1.11 12.27 1 12 1H2c-.55 0-1 .45-1 1v10c0 .27.11.52.29.71l8.59 8.58c.57.57 1.32.88 2.12.88s1.55-.31 2.12-.88l7.17-7.17a3.009 3.009 0 00.01-4.24zm-1.42 2.82l-7.17 7.17c-.39.39-1.02.39-1.42 0L3 11.59V3h8.59l8.29 8.29c.39.39.39 1.03 0 1.41z" /><path d="M7.01 6C6.45 6 6 6.45 6 7s.45 1 1 1 1-.45 1-1-.44-1-.99-1z" /></g></svg>
        </a>
        <span class="mr-2"><a href="/tags/python/" class="no-link inline-flex items-center justify-center font-medium leading-none whitespace-nowrap text-blue-500 dark:text-blue-400 border border-blue-500 dark:border-blue-400 hover:bg-blue-100 dark:hover:bg-transparent dark:hover:border-blue-200 dark:hover:text-blue-200 transition-colors duration-200 ease-out h-6 px-2 text-xs rounded-md">
    <span>python</span>
</a></span>
        <span class="mr-2"><a href="/tags/machine-learning/" class="no-link inline-flex items-center justify-center font-medium leading-none whitespace-nowrap text-blue-500 dark:text-blue-400 border border-blue-500 dark:border-blue-400 hover:bg-blue-100 dark:hover:bg-transparent dark:hover:border-blue-200 dark:hover:text-blue-200 transition-colors duration-200 ease-out h-6 px-2 text-xs rounded-md">
    <span>machine learning</span>
</a></span>
        <span class="mr-2"><a href="/tags/matrix-factorization/" class="no-link inline-flex items-center justify-center font-medium leading-none whitespace-nowrap text-blue-500 dark:text-blue-400 border border-blue-500 dark:border-blue-400 hover:bg-blue-100 dark:hover:bg-transparent dark:hover:border-blue-200 dark:hover:text-blue-200 transition-colors duration-200 ease-out h-6 px-2 text-xs rounded-md">
    <span>matrix factorization</span>
</a></span>
    </span>
</div>


                <!-- Required only on API pages -->
                <doc-toolbar-member-filter-no-results />
            </div>

            
<nav class="flex mt-14">
    <div class="w-1/2">
        <a class="px-5 py-4 h-full flex items-center break-all md:break-normal font-medium text-blue-500 dark:text-blue-400 border border-gray-300 hover:border-gray-400 dark:border-dark-650 dark:hover:border-dark-450 rounded-l-lg transition-colors duration-150 relative hover:z-5" href="/2017/06/17/python-sequence-labelling-with-crf.html/">
            <svg xmlns="http://www.w3.org/2000/svg" class="mr-3" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" overflow="visible"><path d="M19 11H7.41l5.29-5.29a.996.996 0 10-1.41-1.41l-7 7a1 1 0 000 1.42l7 7a1.024 1.024 0 001.42-.01.996.996 0 000-1.41L7.41 13H19c.55 0 1-.45 1-1s-.45-1-1-1z" /><path fill="none" d="M0 0h24v24H0z" /></svg>
            <span>
                <span class="block text-xs font-normal text-gray-400 dark:text-dark-400">Previous</span>
                <span class="block mt-1">Performing Sequence Labelling using CRF in Python</span>
            </span>
        </a>
    </div>

    <div class="w-1/2">
        <a class="px-5 py-4 -mx-px h-full flex items-center justify-end break-all md:break-normal font-medium text-blue-500 dark:text-blue-400 border border-gray-300 hover:border-gray-400 dark:border-dark-650 dark:hover:border-dark-450 rounded-r-lg transition-colors duration-150 relative hover:z-5" href="/2007/05/04/einstein-house.html/">
            <span>
                <span class="block text-xs font-normal text-right text-gray-400 dark:text-dark-400">Next</span>
                <span class="block mt-1">愛因斯坦與伯恩</span>
            </span>
            <svg xmlns="http://www.w3.org/2000/svg" class="ml-3" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" overflow="visible"><path d="M19.92 12.38a1 1 0 00-.22-1.09l-7-7a.996.996 0 10-1.41 1.41l5.3 5.3H5c-.55 0-1 .45-1 1s.45 1 1 1h11.59l-5.29 5.29a.996.996 0 000 1.41c.19.2.44.3.7.3s.51-.1.71-.29l7-7c.09-.09.16-.21.21-.33z" /><path fill="none" d="M0 0h24v24H0z" /></svg>
        </a>
    </div>
</nav>


        </main>

        <div class="border-t dark:border-dark-650 pt-6 mb-8">
            <footer class="flex flex-wrap items-center justify-between">
    <div>
        <ul class="flex flex-wrap items-center text-sm">
</ul>

    </div>
    <div class="docs-copyright py-2 text-gray-500 dark:text-dark-350 text-sm leading-relaxed"><p>© Copyright 2021. All rights reserved.</p>
</div>
</footer>

        </div>
    </div>
    
    <!-- Rendered if sidebar right is enabled -->
    <!-- Sidebar right skeleton-->
    <div v-cloak class="fixed top-0 bottom-0 right-0 transform translate-x-full bg-white border-gray-200 lg:sticky lg:border-l lg:flex-shrink-0 lg:pt-6 lg:transform-none lg:w-56 lg:z-0 md:w-72 sidebar-right skeleton dark:bg-dark-850 dark:border-dark-650">
        <div class="pl-5">
            <div class="w-32 h-3 mb-4 bg-gray-200 dark:bg-dark-600 rounded-full loading"></div>
            <div class="w-48 h-3 mb-4 bg-gray-200 dark:bg-dark-600 rounded-full loading"></div>
            <div class="w-40 h-3 mb-4 bg-gray-200 dark:bg-dark-600 rounded-full loading"></div>
        </div>
    </div>
    
    <!-- User should be able to hide sidebar right -->
    <doc-sidebar-right v-cloak></doc-sidebar-right>
</div>

        </div>
    </div>

    <doc-search-mobile></doc-search-mobile>
    <doc-back-to-top></doc-back-to-top>
</div>


        <div id="docs-overlay-target"></div>

        <script>window.__DOCS__ = { "title": "Matrix Factorization: A Simple Tutorial and Implementation in Python", icon: "file", hasPrism: true, hasMermaid: false, hasMath: true }</script>
    </body>
</html>
